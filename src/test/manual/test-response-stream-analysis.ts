/**
 * å“åº”æµå¤„ç†æ·±åº¦åˆ†ææµ‹è¯•
 * 
 * ç›®æ ‡ï¼šæ·±å…¥ç ”ç©¶specialistçš„å“åº”æµå¤„ç†æœºåˆ¶ï¼ŒéªŒè¯token limité”™è¯¯ä¸ç©ºå“åº”çš„å…³ç³»
 */

// æ¨¡æ‹Ÿ LanguageModelError
class MockLanguageModelError extends Error {
    public code?: string;
    
    constructor(message: string, code?: string) {
        super(message);
        this.name = 'LanguageModelError';
        this.code = code;
        Object.setPrototypeOf(this, MockLanguageModelError.prototype);
    }
}

// æ¨¡æ‹Ÿ VSCode çš„å“åº”æµæ¥å£
interface MockChatResponse {
    text: AsyncIterable<string>;
}

/**
 * åœºæ™¯1: Token limité”™è¯¯å¯¼è‡´å®Œå…¨æ— æ³•è·å–å“åº”æµ
 */
class TokenLimitErrorBeforeStreamModel {
    public name = 'gpt-4-test';
    
    async sendRequest(): Promise<MockChatResponse> {
        // æ¨¡æ‹Ÿï¼štoken limité”™è¯¯åœ¨è·å–å“åº”æµä¹‹å‰å°±æŠ›å‡º
        throw new MockLanguageModelError('Message exceeds token limit.', 'context_length_exceeded');
    }
}

/**
 * åœºæ™¯2: å¼€å§‹å“åº”æµä½†ç«‹å³å› token limitä¸­æ–­
 */
class TokenLimitErrorDuringStreamModel {
    public name = 'gpt-4-test';
    
    async sendRequest(): Promise<MockChatResponse> {
        return {
            text: this.createInterruptedStream()
        };
    }
    
    private async* createInterruptedStream(): AsyncIterable<string> {
        // æ¨¡æ‹Ÿï¼šå“åº”æµå¼€å§‹ä½†ç«‹å³å› token limitä¸­æ–­
        yield 'Starting response...';
        throw new MockLanguageModelError('Message exceeds token limit during processing.', 'context_length_exceeded');
    }
}

/**
 * åœºæ™¯3: å“åº”æµæ­£å¸¸å¯åŠ¨ä½†æä¾›ç©ºå†…å®¹
 */
class EmptyStreamModel {
    public name = 'gpt-4-test';
    
    async sendRequest(): Promise<MockChatResponse> {
        return {
            text: this.createEmptyStream()
        };
    }
    
    private async* createEmptyStream(): AsyncIterable<string> {
        // å®Œå…¨ç©ºçš„å“åº”æµï¼Œæ²¡æœ‰ä»»ä½•å†…å®¹
        return;
    }
}

/**
 * åœºæ™¯4: å“åº”æµæä¾›ç©ºç™½å­—ç¬¦
 */
class WhitespaceOnlyStreamModel {
    public name = 'gpt-4-test';
    
    async sendRequest(): Promise<MockChatResponse> {
        return {
            text: this.createWhitespaceStream()
        };
    }
    
    private async* createWhitespaceStream(): AsyncIterable<string> {
        yield '   ';  // åªæœ‰ç©ºç™½å­—ç¬¦
        yield '\n\n';
        yield '  \t  ';
    }
}

/**
 * æ¨¡æ‹Ÿspecialistçš„å“åº”æµå¤„ç†é€»è¾‘
 * åŸºäºspecialistExecutor.tsç¬¬1550-1610è¡Œ
 */
async function simulateSpecialistResponseProcessing(
    model: any,
    messages: any[],
    requestOptions: any,
    specialistId: string,
    iteration: number
): Promise<{
    success: boolean;
    result?: string;
    errorType: 'no_error' | 'token_limit_before_stream' | 'token_limit_during_stream' | 'empty_response' | 'other_error';
    errorMessage?: string;
    streamFragments?: string[];
}> {
    let retryCount = 0;
    const maxRetries = 3;
    const streamFragments: string[] = [];
    
    console.log(`\nğŸ” === æ¨¡æ‹ŸSpecialistå“åº”æµå¤„ç† ===`);
    console.log(`specialist: ${specialistId}, iteration: ${iteration}`);
    
    while (retryCount <= maxRetries) {
        try {
            // 1. å‘é€è¯·æ±‚è·å–å“åº”
            console.log(`ğŸ“¡ å°è¯•å‘é€è¯·æ±‚åˆ°AIæ¨¡å‹...`);
            const response = await model.sendRequest(messages, requestOptions);
            
            // 2. å¤„ç†AIå“åº”æµ
            console.log(`ğŸ”„ å¼€å§‹å¤„ç†AIå“åº”æµ...`);
            let result = '';
            let fragmentCount = 0;
            
            try {
                for await (const fragment of response.text) {
                    fragmentCount++;
                    result += fragment;
                    streamFragments.push(fragment);
                    console.log(`  ğŸ“¦ æ”¶åˆ°fragment ${fragmentCount}: "${fragment}" (length: ${fragment.length})`);
                }
                
                console.log(`âœ… å“åº”æµå¤„ç†å®Œæˆã€‚æ€»fragments: ${fragmentCount}, æœ€ç»ˆé•¿åº¦: ${result.length}`);
                console.log(`ğŸ“„ å®Œæ•´å“åº”: "${result}"`);
                
                // 3. å…³é”®æ£€æŸ¥ï¼šç©ºå“åº”åˆ¤æ–­
                if (!result.trim()) {
                    console.log(`âŒ æ£€æµ‹åˆ°ç©ºå“åº” (result.trim() === false)`);
                    return {
                        success: false,
                        result: result,
                        errorType: 'empty_response',
                        errorMessage: `ä¸“å®¶ ${specialistId} åœ¨è¿­ä»£ ${iteration} è¿”å›äº†ç©ºå“åº”`,
                        streamFragments
                    };
                }
                
                return {
                    success: true,
                    result: result,
                    errorType: 'no_error',
                    streamFragments
                };
                
            } catch (streamError) {
                const errorMessage = (streamError as Error).message;
                console.log(`âŒ å“åº”æµå¤„ç†ä¸­å‘ç”Ÿé”™è¯¯: ${errorMessage}`);
                
                // å¦‚æœåœ¨å¤„ç†å“åº”æµæ—¶å‘ç”Ÿtoken limité”™è¯¯
                if (streamError instanceof MockLanguageModelError) {
                    return {
                        success: false,
                        errorType: 'token_limit_during_stream',
                        errorMessage: streamError.message,
                        streamFragments
                    };
                }
                
                throw streamError;  // é‡æ–°æŠ›å‡ºétoken limité”™è¯¯
            }
            
        } catch (error) {
            const errorMessage = (error as Error).message;
            console.log(`âŒ å‘é€è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: ${errorMessage}`);
            
            // å¦‚æœæ˜¯åœ¨å‘é€è¯·æ±‚é˜¶æ®µçš„token limité”™è¯¯
            if (error instanceof MockLanguageModelError) {
                console.log(`ğŸ” æ£€æµ‹åˆ°LanguageModelError: ${error.message}`);
                
                // è¿™é‡Œåº”è¯¥ä¼šè¿›å…¥é‡è¯•é€»è¾‘ï¼Œä½†ç”±äºtoken limité€šå¸¸ä¸å¯é‡è¯•...
                // è®©æˆ‘ä»¬æ¨¡æ‹Ÿé”™è¯¯åˆ†ç±»
                const classification = classifyNetworkErrorForTest(error);
                
                if (classification.retryable && retryCount < classification.maxRetries) {
                    retryCount++;
                    console.log(`ğŸ”„ é”™è¯¯å¯é‡è¯•ï¼Œé‡è¯• ${retryCount}/${classification.maxRetries}`);
                    continue;
                } else {
                    console.log(`âŒ é”™è¯¯ä¸å¯é‡è¯•æˆ–é‡è¯•æ¬¡æ•°è€—å°½`);
                    return {
                        success: false,
                        errorType: 'token_limit_before_stream',
                        errorMessage: error.message,
                        streamFragments
                    };
                }
            }
            
            return {
                success: false,
                errorType: 'other_error',
                errorMessage: errorMessage,
                streamFragments
            };
        }
    }
    
    return {
        success: false,
        errorType: 'other_error',
        errorMessage: 'è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°',
        streamFragments
    };
}

/**
 * ç®€åŒ–çš„é”™è¯¯åˆ†ç±»å‡½æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
 */
function classifyNetworkErrorForTest(error: Error) {
    const message = error.message.toLowerCase();
    
    // Token limité”™è¯¯é€šå¸¸ä¸å¯é‡è¯•
    if (message.includes('token limit') || 
        message.includes('exceeds') && message.includes('limit') ||
        message.includes('context length')) {
        return {
            retryable: false,
            maxRetries: 0,
            errorCategory: 'config',
            userMessage: 'Token limit exceeded'
        };
    }
    
    // å…¶ä»–é”™è¯¯å¯èƒ½å¯é‡è¯•
    return {
        retryable: true,
        maxRetries: 2,
        errorCategory: 'unknown',
        userMessage: 'Unknown error'
    };
}

/**
 * æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯
 */
async function runResponseStreamAnalysis() {
    console.log('ğŸ§ª === å“åº”æµå¤„ç†æ·±åº¦åˆ†ææµ‹è¯• ===\n');
    
    const testCases = [
        {
            name: 'åœºæ™¯1: Token limité”™è¯¯åœ¨è·å–å“åº”æµå‰æŠ›å‡º',
            model: new TokenLimitErrorBeforeStreamModel(),
            description: 'æ¨¡æ‹Ÿtoken limité”™è¯¯åœ¨model.sendRequest()é˜¶æ®µå°±æŠ›å‡º'
        },
        {
            name: 'åœºæ™¯2: Token limité”™è¯¯åœ¨å“åº”æµå¤„ç†ä¸­æŠ›å‡º', 
            model: new TokenLimitErrorDuringStreamModel(),
            description: 'æ¨¡æ‹Ÿå“åº”æµå¼€å§‹ä½†åœ¨å¤„ç†è¿‡ç¨‹ä¸­å› token limitä¸­æ–­'
        },
        {
            name: 'åœºæ™¯3: å“åº”æµæ­£å¸¸ä½†å®Œå…¨æ— å†…å®¹',
            model: new EmptyStreamModel(),
            description: 'æ¨¡æ‹Ÿå“åº”æµæ­£å¸¸å¯åŠ¨ä½†æ²¡æœ‰äº§ç”Ÿä»»ä½•å†…å®¹'
        },
        {
            name: 'åœºæ™¯4: å“åº”æµåªäº§ç”Ÿç©ºç™½å­—ç¬¦',
            model: new WhitespaceOnlyStreamModel(),
            description: 'æ¨¡æ‹Ÿå“åº”æµäº§ç”Ÿå†…å®¹ä½†åªæœ‰ç©ºç™½å­—ç¬¦'
        }
    ];
    
    const results = [];
    
    for (let i = 0; i < testCases.length; i++) {
        const testCase = testCases[i];
        console.log(`\nğŸ“‹ ${testCase.name}`);
        console.log(`ğŸ” ${testCase.description}`);
        
        const result = await simulateSpecialistResponseProcessing(
            testCase.model,
            [{ role: 'user', content: 'test message' }],
            { justification: 'test' },
            'test_specialist',
            1
        );
        
        results.push({
            testCase: testCase.name,
            ...result
        });
        
        console.log(`\nğŸ“Š ç»“æœ:`)
        console.log(`  - æˆåŠŸ: ${result.success}`);
        console.log(`  - é”™è¯¯ç±»å‹: ${result.errorType}`);
        console.log(`  - é”™è¯¯æ¶ˆæ¯: ${result.errorMessage || 'none'}`);
        console.log(`  - æµç‰‡æ®µæ•°: ${result.streamFragments?.length || 0}`);
        if (result.streamFragments && result.streamFragments.length > 0) {
            console.log(`  - æµç‰‡æ®µ: ${JSON.stringify(result.streamFragments)}`);
        }
    }
    
    // åˆ†æç»“æœ
    console.log('\nğŸ¯ === å…³é”®å‘ç°åˆ†æ ===');
    
    const tokenLimitBeforeStream = results.find(r => r.errorType === 'token_limit_before_stream');
    const tokenLimitDuringStream = results.find(r => r.errorType === 'token_limit_during_stream');
    const emptyResponse = results.find(r => r.errorType === 'empty_response');
    
    console.log('\n1ï¸âƒ£ Token Limité”™è¯¯çš„ä¸åŒé˜¶æ®µå½±å“:');
    if (tokenLimitBeforeStream) {
        console.log(`  âœ… å‘ç°: Token limitåœ¨sendRequesté˜¶æ®µæŠ›å‡º â†’ ${tokenLimitBeforeStream.errorType}`);
        console.log(`  ğŸ“ è¿™ç§æƒ…å†µä¸‹specialistä¼šæ•è·LanguageModelErrorï¼Œä¸ä¼šè¯¯åˆ¤ä¸ºç©ºå“åº”`);
    }
    
    if (tokenLimitDuringStream) {
        console.log(`  âœ… å‘ç°: Token limitåœ¨å“åº”æµå¤„ç†ä¸­æŠ›å‡º â†’ ${tokenLimitDuringStream.errorType}`);
        console.log(`  ğŸ“ è¿™ç§æƒ…å†µå¯èƒ½æ›´å¤æ‚ï¼Œå› ä¸ºå·²ç»å¼€å§‹å¤„ç†å“åº”æµ`);
        console.log(`  ğŸ“ å·²æ¥æ”¶çš„ç‰‡æ®µ: ${tokenLimitDuringStream.streamFragments?.length || 0}ä¸ª`);
    }
    
    console.log('\n2ï¸âƒ£ ç©ºå“åº”vsçœŸæ­£çš„Token Limité”™è¯¯:');
    if (emptyResponse) {
        console.log(`  âœ… å‘ç°: çœŸæ­£çš„ç©ºå“åº”æµ â†’ ${emptyResponse.errorType}`);
        console.log(`  ğŸ“ è¿™ç§æƒ…å†µä¼šè¢«295-298è¡Œçš„æ£€æŸ¥æ•è·ï¼ŒæŠ¥å‘Šä¸º"ç©ºå“åº”"`);
    }
    
    console.log('\n3ï¸âƒ£ å…³é”®é—®é¢˜éªŒè¯:');
    console.log('â“ Token limité”™è¯¯æ˜¯å¦å¯èƒ½è¢«è¯¯åˆ¤ä¸ºç©ºå“åº”ï¼Ÿ');
    
    const couldBeMisidentified = results.some(r => 
        (r.errorType === 'token_limit_before_stream' || r.errorType === 'token_limit_during_stream') &&
        r.errorMessage?.includes('ç©ºå“åº”')
    );
    
    if (couldBeMisidentified) {
        console.log('  âš ï¸  ç¡®è®¤: å­˜åœ¨token limité”™è¯¯è¢«è¯¯åˆ¤ä¸ºç©ºå“åº”çš„æƒ…å†µ');
    } else {
        console.log('  âœ… ç»“æœ: åœ¨å½“å‰æµ‹è¯•ä¸­ï¼Œtoken limité”™è¯¯æ²¡æœ‰è¢«è¯¯åˆ¤ä¸ºç©ºå“åº”');
        console.log('  ğŸ’¡ å¯èƒ½çš„æƒ…å†µ:');
        console.log('    - Token limité”™è¯¯ä¼šè¢«æ­£ç¡®è¯†åˆ«ä¸ºLanguageModelError');
        console.log('    - åªæœ‰çœŸæ­£çš„ç©ºå“åº”æµæ‰ä¼šè§¦å‘"ç©ºå“åº”"æ£€æŸ¥');
        console.log('    - ç”¨æˆ·è§‚å¯Ÿåˆ°çš„ç°è±¡å¯èƒ½æ¥è‡ªå…¶ä»–æ›´å¤æ‚çš„åœºæ™¯');
    }
    
    console.log('\n4ï¸âƒ£ éœ€è¦è¿›ä¸€æ­¥éªŒè¯çš„æƒ…å†µ:');
    console.log('  1. ç½‘ç»œä¸­æ–­å¯¼è‡´çš„éƒ¨åˆ†å“åº”æµ');
    console.log('  2. AIæœåŠ¡çš„ç‰¹æ®Šé”™è¯¯å“åº”æ ¼å¼');
    console.log('  3. VSCode Language Model APIçš„ç‰¹å®šè¡Œä¸º');
    console.log('  4. è¶…é•¿è¾“å…¥å¯¼è‡´çš„truncationè¡Œä¸º');
    
    return results;
}

// è¿è¡Œæµ‹è¯•
if (require.main === module) {
    runResponseStreamAnalysis()
        .then((results) => {
            console.log('\nâœ… å“åº”æµåˆ†ææµ‹è¯•å®Œæˆ');
            console.log(`ğŸ“Š æ€»å…±æµ‹è¯• ${results.length} ä¸ªåœºæ™¯`);
        })
        .catch((error) => {
            console.error('âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥:', error);
            process.exit(1);
        });
}

export { runResponseStreamAnalysis };

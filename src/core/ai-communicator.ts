import * as vscode from 'vscode';
import { IAICommunicator } from '../types';
import { Logger } from '../utils/logger';
import { ErrorHandler } from '../utils/error-handler';
import { PromptManager } from './prompt-manager';

/**
 * AIé€šä¿¡ç®¡ç†å™¨ï¼ˆé™çº§å¤‡ç”¨ç»„ä»¶ï¼‰
 * è´Ÿè´£ä¸VSCode Language Model APIçš„äº¤äº’
 * 
 * âš ï¸ é‡è¦ï¼šæ­¤ç»„ä»¶ä»…ä½œä¸ºé™çº§å¤‡ç”¨ï¼Œå½“ç›´æ¥VSCode APIè°ƒç”¨ä¸å¯ç”¨æ—¶ä½¿ç”¨
 * ğŸš« è¯·å‹¿åˆ é™¤æ­¤æ³¨é‡Šå’Œç±» - è¿™æ˜¯ç³»ç»Ÿç¨³å®šæ€§çš„é‡è¦ä¿éšœ
 * ğŸ“‹ ä¸»è¦è·¯å¾„åº”ä½¿ç”¨ SpecialistExecutor ç›´æ¥è°ƒç”¨ VSCode API
 * ğŸ”„ æœªæ¥ç‰ˆæœ¬å¯èƒ½ä¼šç§»é™¤æ­¤é™çº§æœºåˆ¶
 */
export class AICommunicator implements IAICommunicator {
    private logger = Logger.getInstance();
    private promptManager = new PromptManager();

    /**
     * åŸºäºç”¨æˆ·è¾“å…¥ç”Ÿæˆæ¯æ–‡æ¡£
     * @param userInput ç”¨æˆ·çš„åŸå§‹éœ€æ±‚å­—ç¬¦ä¸²
     * @returns Promise<string> AIç”Ÿæˆçš„å®Œæ•´æ¯æ–‡æ¡£å†…å®¹
     */
    public async generateMotherDocument(userInput: string): Promise<string> {
        this.logger.info('Starting mother document generation');
        
        try {
            // æ£€æŸ¥Language Modelæ˜¯å¦å¯ç”¨
            const models = await vscode.lm.selectChatModels();
            if (models.length === 0) {
                throw new Error('No language models available. Please configure GitHub Copilot or another supported AI provider.');
            }

            // é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹
            const model = models[0];
            this.logger.info(`Using language model: ${model.name} (${model.vendor})`);

            // å‡†å¤‡æ ¸å¿ƒPrompt
            const systemPrompt = this.promptManager.getSystemPrompt();
            const userPrompt = this.promptManager.getUserPrompt(userInput);

            // æ„å»ºèŠå¤©æ¶ˆæ¯
            const messages = [
                vscode.LanguageModelChatMessage.User(systemPrompt),
                vscode.LanguageModelChatMessage.User(userPrompt)
            ];

            // é…ç½®è¯·æ±‚é€‰é¡¹
            const requestOptions: vscode.LanguageModelChatRequestOptions = {
                justification: 'Generate structured SRS document based on user requirements'
            };

            this.logger.info('Sending request to language model...');

            // å‘é€è¯·æ±‚åˆ°è¯­è¨€æ¨¡å‹
            const response = await model.sendRequest(messages, requestOptions);
            
            // æ”¶é›†å®Œæ•´å“åº”
            let motherDocument = '';
            for await (const fragment of response.text) {
                motherDocument += fragment;
            }

            if (!motherDocument.trim()) {
                throw new Error('Language model returned empty response');
            }

            this.logger.info(`Mother document generated successfully, length: ${motherDocument.length}`);
            
            // éªŒè¯æ¯æ–‡æ¡£çš„åŸºæœ¬ç»“æ„
            this.validateMotherDocument(motherDocument);
            
            return motherDocument;

        } catch (error) {
            this.logger.error('Failed to generate mother document', error as Error);
            
            if (error instanceof Error) {
                // å¤„ç†ç‰¹å®šç±»å‹çš„é”™è¯¯
                if (error.message.includes('No language models available')) {
                    throw new Error('è¯·å…ˆé…ç½®AIæ¨¡å‹ï¼ˆå¦‚GitHub Copilotï¼‰åå†ä½¿ç”¨SRS Writeræ’ä»¶ã€‚');
                } else if (error.message.includes('rate limit') || error.message.includes('quota')) {
                    throw new Error('AIæœåŠ¡è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•ã€‚');
                } else if (error.message.includes('network') || error.message.includes('timeout')) {
                    throw new Error('ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚');
                }
            }
            
            throw error;
        }
    }

    /**
     * éªŒè¯æ¯æ–‡æ¡£çš„åŸºæœ¬æ ¼å¼
     */
    private validateMotherDocument(motherDocument: string): void {
        // æ£€æŸ¥å¿…è¦çš„ç« èŠ‚æ ‡è¯†ç¬¦
        const requiredSections = [
            '--- SOFTWARE REQUIREMENTS SPECIFICATION ---',
            '--- FUNCTIONAL REQUIREMENTS ---',
            '--- NON-FUNCTIONAL REQUIREMENTS ---',
            '--- GLOSSARY ---'
        ];

        const missingPages = requiredSections.filter(section => 
            !motherDocument.includes(section)
        );

        if (missingPages.length > 0) {
            this.logger.warn(`Mother document missing sections: ${missingPages.join(', ')}`);
            // ä¸æŠ›å‡ºé”™è¯¯ï¼Œè€Œæ˜¯è®°å½•è­¦å‘Šï¼Œå› ä¸ºä¼˜é›…é™çº§ç­–ç•¥ä¼šå¤„ç†ç¼ºå¤±çš„éƒ¨åˆ†
        }

        // æ£€æŸ¥åŸºæœ¬é•¿åº¦
        if (motherDocument.length < 500) {
            this.logger.warn('Mother document seems too short, might be incomplete');
        }

        this.logger.info('Mother document validation completed');
    }

    /**
     * æ£€æŸ¥Language Model APIçš„å¯ç”¨æ€§
     */
    public async checkAvailability(): Promise<boolean> {
        try {
            const models = await vscode.lm.selectChatModels();
            return models.length > 0;
        } catch (error) {
            this.logger.error('Failed to check language model availability', error as Error);
            return false;
        }
    }

    /**
     * è·å–å¯ç”¨çš„è¯­è¨€æ¨¡å‹åˆ—è¡¨
     */
    public async getAvailableModels(): Promise<vscode.LanguageModelChat[]> {
        try {
            return await vscode.lm.selectChatModels();
        } catch (error) {
            this.logger.error('Failed to get available models', error as Error);
            return [];
        }
    }

    /**
     * è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
     */
    public async getCurrentModelInfo(): Promise<string> {
        try {
            const models = await vscode.lm.selectChatModels();
            if (models.length === 0) {
                return 'No models available';
            }
            
            const model = models[0];
            return `${model.name} (${model.vendor}) - Max Input: ${model.maxInputTokens}, Max Output: ${model.maxInputTokens}`;
        } catch (error) {
            this.logger.error('Failed to get model info', error as Error);
            return 'Unknown';
        }
    }

    /**
     * æ‰§è¡Œ.mdcè§„åˆ™æ–‡ä»¶ - v1.3æœ€ç»ˆç‰ˆ
     * @param ruleContent å¡«å……å¥½çš„è§„åˆ™å†…å®¹
     * @param model ç”¨æˆ·åœ¨UIä¸Šé€‰æ‹©çš„ã€ç”±å¤–éƒ¨ä¼ å…¥çš„æ¨¡å‹å®ä¾‹
     * @returns Promise<string> AIçš„å“åº”ç»“æœ
     */
    public async executeRule(ruleContent: string, model?: vscode.LanguageModelChat): Promise<string> {
        this.logger.info(`Executing rule with user-selected model: ${model?.name || 'fallback'}`);
        
        try {
            let selectedModel: vscode.LanguageModelChat;
            
            if (model) {
                // ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
                selectedModel = model;
                this.logger.info(`Using user-selected model: ${model.name}`);
            } else {
                // é™çº§æ–¹æ¡ˆï¼šå¦‚æœæ²¡æœ‰ä¼ å…¥æ¨¡å‹ï¼Œåˆ™è‡ªåŠ¨é€‰æ‹©
                const models = await vscode.lm.selectChatModels();
                if (models.length === 0) {
                    throw new Error('No language models available for rule execution.');
                }
                selectedModel = models[0];
                this.logger.warn(`No model provided, using fallback: ${selectedModel.name}`);
            }

            // ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„modelå®ä¾‹å‘é€è¯·æ±‚
            const messages = [
                vscode.LanguageModelChatMessage.User(ruleContent)
            ];

            const requestOptions: vscode.LanguageModelChatRequestOptions = {
                justification: 'Execute SRS Writer rule for intelligent content generation'
            };

            // å‘é€è¯·æ±‚
            const response = await selectedModel.sendRequest(messages, requestOptions);
            
            // æ”¶é›†å“åº”
            let result = '';
            for await (const fragment of response.text) {
                result += fragment;
            }

            if (!result.trim()) {
                throw new Error('Rule execution returned empty response');
            }

            this.logger.info(`Rule executed successfully with ${selectedModel.name}, response length: ${result.length}`);
            return result;

        } catch (error) {
            this.logger.error(`Failed to execute rule with model ${model?.name || 'unknown'}`, error as Error);
            throw error;
        }
    }
}
